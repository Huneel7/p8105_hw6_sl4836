---
title: "p8105_hw6_sl4836"
author: "Hun"
date: "12/2/2021"
output: github_document
---

```{r}
library(tidyverse)
library(janitor)
library(rstatix)
library(egg)
library(modelr)
library(PerformanceAnalytics)
library(robmed)
```


### Problem 0 - Creating a subdirectory
```{r}
dir.create(file.path(getwd(), "hw6_data_file"), recursive = TRUE)
```

### Problem 1 Importing data
```{r}
birthweight_data <- read_csv("./hw6_data_file/birthweight.csv")
```

### Problem 1 Tidying and wrangling the data
```{r}
cleaned_birthweight_data <-
  birthweight_data %>% 
  janitor::clean_names() %>%
  mutate(across(.cols = c(babysex, frace, malform, mrace), as.factor)) %>%
  mutate(babysex = ifelse(babysex == "1", "male","female"),
         malform = ifelse(malform == "0", "absent","present"),
         frace = recode(frace, "1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
         mrace = recode(mrace, "1" = "White", "2" = "Black", 
                        "3" = "Asian", "4" = "Puerto Rican", "8" = "Other")
         )
```

### Checking Missing Values and the summary of the dataset
```{r}
skimr::skim(cleaned_birthweight_data)

birthweight_data_variables <- names(birthweight_data)
birthweight_data_nrow <- nrow(birthweight_data)
birthweight_data_ncol <- ncol(birthweight_data)
```

There are no missing values in the dataset. The dimension of the birthweight data is **`r birthweight_data_nrow` x**  **`r birthweight_data_ncol`.** There are **`r birthweight_data_nrow`** number of observations and **`r birthweight_data_ncol`**  variables: *`r birthweight_data_variables`.* 

### Computing Correlation Matrix
```{r, warning = FALSE}
birthweight_data %>% 
  cor_mat() %>%
  cor_gather() %>%
  filter(var1 %in% "bwt") %>%
  filter(!var2 %in% "bwt") %>%
  mutate(
    sig_p = ifelse(p < 0.01, T, F),
    cor_if_sig = ifelse(p < 0.01, cor, NA)
    ) %>% 
  ggplot(aes(
    x = var1, 
    y = var2, 
    fill = cor,
    label = round(cor_if_sig, 2))) + 
  geom_tile(color = "white") +   
  geom_text(
    color = "white",
    size = 4
  ) + 
  scale_x_discrete(
    labels = c("Birth Weight")
  ) + 
  labs(
    x = "Outcome Variable",
    y = "Predictor Variables",
    title = "Correlation Matrix between Predictors and Outcome",
    subtitle = "significant predictors at significance level 0.01",
    fill = "Correlation"
  )

continuous_variables <-  
  cleaned_birthweight_data %>%
  select_if(is.numeric) %>%
  select(-bwt, -ppbmi, -ppwt, -pnumsga, -parity, -pnumlbw) %>%
  colnames() %>% 
  as.vector()
```

Computing pearson correlation matrix with p-values based on T-test for correlation coefficient. Based on this correlation matrix, I selected continuous variables to be used to fit a scatterplot against the outcome variable in order to check lienar trends between continuous predictors and the outcome variable. The selected variables are: *`r continuous_variables`.*


### Fitting scatterplots with selected predictors against birthweight to see if there is a linear trend between continuous predictors and the outcome variable
```{r}
continuous_variables <- 
  continuous_variables %>%
  as.list()

for (i in continuous_variables) {
  plot <-
  ggplot(cleaned_birthweight_data, aes_string(i,  "bwt")) + 
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  labs(title = "Scatterplot", y = "Birth Weight") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
  print(plot) 
}


```



### Selecting final numerical independent variables based on the information obtained from the correaltion matrix and scatterplots in order to check correlation between predictors and potential interactions between them. 
```{r}
numerical_variables <-
  cleaned_birthweight_data %>%
  select(bhead, blength, delwt, gaweeks, wtgain, bwt)

chart.Correlation(numerical_variables, method = "pearson")
```


### Final Selection of predictors to fit linear regression.
```{r}
selected_variables <-
  cleaned_birthweight_data %>%
  select(bhead, blength, delwt, gaweeks, wtgain, bwt, 
         babysex, mrace)
```


### Fitting my model with two interaction terms and checking if my model meets the assumptions for linear regression
```{r}
fit1 <- lm(bwt ~ bhead + blength + gaweeks + babysex + mrace + bhead:blength +
             bhead:blength:gaweeks, 
           data = selected_variables)
```

### Fitting the plot of my model residuals against fitted values
```{r, warning = FALSE}
selected_variables %>%
  add_residuals(fit1) %>%
  add_predictions(fit1) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Plot of the model residuals against fitted values",
       x= "Fitted values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```

### Computing rmse of models through cross validaiton
```{r}
set.seed(77)

cv_dataset <-
  selected_variables %>% 
  crossv_mc(n = 100,test = 0.2)
  

cv_df <- 
  cv_dataset %>%
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df <-
  cv_df %>%
    mutate(
    linear_mod1  = map(train, ~lm(bwt ~ bhead + blength + gaweeks + babysex + mrace 
                                  + bhead:blength + bhead:blength:gaweeks, 
                                  data = .x)),
    linear_mod2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    linear_mod3  = map(train, ~lm(bwt ~ (bhead + blength + babysex)^3, data = .x))
    ) %>%
   mutate(
    rmse_my_model = map2_dbl(linear_mod1, test, ~rmse(model = .x, data = .y)),
    rmse_given_model1 = map2_dbl(linear_mod2, test, ~rmse(model = .x, data = .y)),
    rmse_given_model2 = map2_dbl(linear_mod3, test, ~rmse(model = .x, data = .y))
   )
```


### Fitting the distribution of rmse of the models. 
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot() +
  labs(title = 
  "Model Comparison with respect to the cross-validated prediction error", 
       x = "Models", y = "Root Mean Square Error")  +
  scale_x_discrete(
    labels = c("My Model", "Test Model 1", "Test Model 2")) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

### Problem 2 - Importing data
```{r}
weather_df <- 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### Fitting a given model
```{r}
fit0 <- lm(tmax ~ tmin, data = weather_df)
```

### Generating 5000 bootstraps of the dataset
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps
```

### Generating 5000 bootstrap estimates
```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 
```

# Computing log(Beta_0_hat * Beta_1_hat) and getting 5000 of those estiamtes
```{r}
log_betas <-  
  bootstrap_results %>%
  group_by(strap_number) %>%
  summarise(log_betas = log(estimate[1] * estimate[2])) %>%
  select(log_betas, strap_number)
  
```

### Generating 5000 bootstrap estimates
```{r}
bootstrap_results2 <- 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 
```

# Getting 5000 R-Squared estimates
```{r}
r_squared <- 
  bootstrap_results2 %>%
  select(r.squared, strap_number)
  
```

# Fitting density plots of two estimates
```{r}
log_betas %>%
  ggplot(aes(x = log_betas)) + geom_density()

r_squared %>%
  ggplot(aes(x = r.squared)) + geom_density()
```
# Generating confience interval of two estimates
```{r}
CI_betas <- 
  bootstrap_results %>%
  group_by(term) %>%
  summarize(ci_lower = quantile(estimate, 0.025),
            ci_upper = quantile(estimate, 0.975),
            )

CI_log_betas_lower <- 
  CI_betas %>% 
  summarise(CI_log_betas_lower = log(ci_lower[1] * ci_lower[2]))

CI_log_betas_upper <- 
  CI_betas %>% 
  summarise(CI_log_betas_upper = log(ci_upper[1] * ci_upper[2]))

CI_log_betas <- 
  tibble("95% CI Lower Bound of Log Betas" = as.numeric(CI_log_betas_lower), 
         "95% CI Upper Bound of Log Betas" = as.numeric(CI_log_betas_upper))


CI_log_betas 
```

```{r}
log_betas %>%
  summarize(ci_lower = quantile(log_betas, 0.025),
            ci_upper = quantile(log_betas, 0.975)) %>%
  tibble(
    "95% CI Lower Bound of Log Betas" = as.numeric(ci_lower), 
    "95% CI Upper Bound of Log Betas" = as.numeric(ci_upper)) %>%
  select(-ci_lower, -ci_upper)
```


```{r}
r_squared %>%
  summarize(ci_lower = quantile(r.squared, 0.025),
            ci_upper = quantile(r.squared, 0.975)) %>%
  tibble(
    "95% CI Lower Bound of R-squared" = as.numeric(ci_lower), 
    "95% CI Upper Bound of R-squared" = as.numeric(ci_upper)) %>%
  select(-ci_lower, -ci_upper)
```

```{r}
summary(fit1)
```

